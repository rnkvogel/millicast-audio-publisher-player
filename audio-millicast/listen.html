<!DOCTYPE html>
<html>
	<head>
	<title>Millicast - Realtime Streaming Demo (Viewer)</title>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
	<style>
		audio {
			height: 10%;
			/* width: 100%; */
           filter: sepia(20%) saturate(70%) grayscale(1) contrast(99%) invert(12%);
           width: 200px;
           height: 25px;
		}
		#lddt{
       width: 480px;
       height: 50px;
       text-align:center;
       background-color: rgba(5, 173, 13, 0.49);
        }
 

		
	</style>
	</head>
	<body>
	
	<!-- Standard shim for WebRTC browser compatibility -->
	<script src="adapter-latest.js"></script>
	<div id="container">

   <audio id="lddt" playsinline controls autoplay ></audio>
</div>


  </div>

</div>
<script>
var x = document.getElementById("lddt");



		let params = new URLSearchParams(document.location.search.substring(1));
		const streamId = params.get('streamId');
		console.log('Millicast Viewer Stream: ',streamId);
		//URL to millicast media server
		const url = "wss://live.millicast.com:443/ws/v1/sub";
    const turnUrl = 'https://turn.millicast.com/webrtc/_turn';
		//Ice Servers:
		let iceServers = [];

		function connect() {
			console.log('connecting to: ',url);
			//create Peer connection object
      let conf = {
          iceServers : iceServers,
          // sdpSemantics : "unified-plan",
				  rtcpMuxPolicy : "require",
				  bundlePolicy : "max-bundle"
      };
      console.log('config: ', conf);
      let pc = new RTCPeerConnection( conf );
      //Listen for track once it starts playing.
			pc.ontrack = function(event) {
				console.debug("pc::onAddStream",event);
				//Play it
				let vidWin = document.getElementsByTagName('audio')[0];
				if(vidWin) {
					vidWin.srcObject = event.streams[0];
					vidWin.controls = true;
				}
			};

			//connect with Websockets for handshake to media server.
			let ws = new WebSocket(url);
			ws.onopen = function(){
				//Connect to our media server via WebRTC
				console.log('ws::onopen');
				//if this is supported
				/* if (pc.addTransceiver) {
					console.log('transceiver!');
					//Create dummy stream
					const stream = new MediaStream();
					//Create all the receiver tracks
					pc.addTransceiver("audio",{
						direction       : "recvonly",
							streams         : [stream]
					});
					pc.addTransceiver("video",{
						direction       : "recvonly",
							streams         : [stream]
					});
				} */

				//create a WebRTC offer to send to the media server
				let offer = pc.createOffer({
					offerToReceiveAudio: true,
					offerToReceiveVideo: true

				}).then( desc => {
					console.log('createOffer Success!');
					//set local description and send offer to media server via ws.
					pc.setLocalDescription(desc)
						.then( () => {
							console.log('setLocalDescription Success!');
							//set required information for media server.
							let data = {
								streamId : streamId,//Millicast viewer streamId
								sdp		: desc.sdp

							}
								//feedId	: streamId,
							//create payload
							let payload = {
								type	: "cmd",
								transId	: 0,
								name	: 'view',
								data	: data
							}
							console.log('send ',payload);
							ws.send( JSON.stringify(payload) );
						})
						.catch(e => { 
							console.log('setLocalDescription failed: ',e); 
						})
				}).catch( e => { 
					console.log('createOffer Failed: ',e) 
				});
			}
            
 			ws.addEventListener('message', evt => {
				console.log('ws::message',evt);
				let msg = JSON.parse(evt.data);
				switch(msg.type){
					//Handle counter response coming from the Media Server.
					case "response":
						let data = msg.data;
						     function modifySDP(sdp){        
                        // data.sdp = sdp.replace(/a=mid:video\r\n/g, 'a=mid:video\r\nb=AS:400\r\n');        
                       //data.sdp = sdp.replace(/a=mid:audio\r\n/g, 'a=mid:audio\r\nb=AS:40\r\n');
                      return data.sdp;
                      } 
						let answer = new RTCSessionDescription({
							type: 'answer',
							sdp : data.sdp

						});
                        
						pc.setRemoteDescription(answer)
							.then(d => {
								console.log('setRemoteDescription  Success! ');
							})
							.catch(e => {
								console.log('setRemoteDescription failed: ',e);
							});
						break;
				}
			})
		}

		// Gets ice servers.
		function getICEServers(){
			return new Promise( (resolve, reject) => {
				let xhr = new XMLHttpRequest();
				xhr.onreadystatechange = function(evt){
					if(xhr.readyState == 4) { 
						let res = JSON.parse(xhr.responseText), a;
						console.log('getICEServers::status:',xhr.status,' response: ',xhr.responseText);
						switch(xhr.status){
							case 200:
								//returns array.
								let list = res.v.iceServers;
								a = [];
								//call returns old format, this updates URL to URLS in credentials path.
								list.forEach(cred => {
									let v = cred.url;
									if(!!v) { cred.urls = v; delete cred.url; }
									a.push(cred);
									//console.log('cred:',cred);
								});
								console.log('ice: ',a);
								resolve(a);
								break;
							default:
								a = [];
								//reject(xhr.responseText);
								//failed to get ice servers, resolve anyway to connect w/ out.
								resolve(a);
								break;
						}
					}
				}
				xhr.open("PUT", turnUrl, true);
				xhr.send();
			})
		}



		function ready(){
			let v = document.getElementsByTagName('audio')[0];
			if(v){
				v.addEventListener("click", evt => {
					v.play();
				});
			}
			//connect();

			// get a list of Xirsys ice servers.
			getICEServers()
				.then(list => {
                    iceServers = list;
					//ready to connect.
					connect();
				});
		}

		if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading"){
			ready();
		} else {
			document.addEventListener('DOMContentLoaded', ready );
		}
	</script>
	</body>
		
</html>
